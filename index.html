<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-test-blog" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/test-blog/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:41:47.000Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/09/17/test-blog/">test_blog</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/test-blog/" data-id="cktob6bux0007qgtkhycx1m8p" data-title="test_blog" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/hello-world/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:40:18.337Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/09/17/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/hello-world/" data-id="cktob6bux0006qgtk7klwefnj" data-title="Hello World" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-SuperResolution by FSRCNN" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/SuperResolution%20by%20FSRCNN/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:04:08.947Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="SuperResolution-by-FSRCNN"><a href="#SuperResolution-by-FSRCNN" class="headerlink" title="SuperResolution by FSRCNN"></a>SuperResolution by FSRCNN</h1><p>以下内容基于本人阅读理解</p>
<p>arXiv:1608.00367v1 [cs.CV] 1 Aug 2016</p>
<p>作为卷积网络实现超像素任务的开山鼻祖，虽然已经不是state-of-the-art的网络，但是新的论文还是会把srcnn拿出来diss一轮。</p>
<hr>
<h2 id="论文简介"><a href="#论文简介" class="headerlink" title="论文简介"></a>论文简介</h2><p>srcnn是第一篇用卷积网络做超像素的，效果超过了传统方法，但是计算量大，不能做到实时。fsrcnn基于srcnn，提出了新的网络结构。</p>
<h2 id="srcnn的短板"><a href="#srcnn的短板" class="headerlink" title="srcnn的短板"></a>srcnn的短板</h2><h4 id="预处理过程"><a href="#预处理过程" class="headerlink" title="预处理过程"></a>预处理过程</h4><p>srcnn在第一步就通过bicubic interpolation将输入图像放大n倍（n为超像素的倍数），因此此后进行的非线性映射过程，计算量以n^2倍提升。</p>
<h4 id="非线性映射过程"><a href="#非线性映射过程" class="headerlink" title="非线性映射过程"></a>非线性映射过程</h4><p>非线性映射过程的层数越多，卷积核越大，效果越好，但是计算量也随之增大。</p>
<h2 id="fsrcnn的改进"><a href="#fsrcnn的改进" class="headerlink" title="fsrcnn的改进"></a>fsrcnn的改进</h2><h4 id="引入deconvolution层"><a href="#引入deconvolution层" class="headerlink" title="引入deconvolution层"></a>引入deconvolution层</h4><p>deconv层作为输出层，这样mapping的过程都在low resolution space完成，计算量以n^2倍减少。</p>
<h4 id="引入shrinking和expending"><a href="#引入shrinking和expending" class="headerlink" title="引入shrinking和expending"></a>引入shrinking和expending</h4><p>shrinking减少通道数，expending扩充通道数。因此mapping过程可以叠加多次卷积而计算量也不会很大。</p>
<h4 id="沙漏状的architecture"><a href="#沙漏状的architecture" class="headerlink" title="沙漏状的architecture"></a>沙漏状的architecture</h4><p>一堆卷积操作的叠加实现end-to-end的超像素任务</p>
<h4 id="速度很快"><a href="#速度很快" class="headerlink" title="速度很快"></a>速度很快</h4><p>比srcnn-ex快40倍，fsrcnn-s可以在cpu上做到实时而且效果不比srcnn差</p>
<h4 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h4><p>训练好的网络只需要fintune deconv层就可以实现其他scale factor的sr</p>
<p><a target="_blank" rel="noopener" href="https://ws1.sinaimg.cn/large/006tKfTcgy1g0egsscjvgj314i0fen81.jpg"><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g0egsscjvgj314i0fen81.jpg" alt="fsrcnnArchitecture"></a></p>
<h2 id="Trick"><a href="#Trick" class="headerlink" title="Trick"></a>Trick</h2><ol>
<li>网络按scale factor = 3训练，收敛后只fintune deconv层即可得到其他scale factor（如2，4）。</li>
<li>Augmenation，缩小了0.9到0.6倍以及旋转，数据集增大了20倍</li>
<li>输入的图片需要根据scale factor剪裁成10像素左右的patch（约定俗成？）</li>
<li>论文作者自制了一个数据集：General1000，图片中比较少纯色块的，适合训练sr任务（可是剪出来的patch还是很多色块啊）。训练时用General1000和91images。</li>
<li>BSD500是jpg格式的，不适合做sr</li>
<li>feature extraction用5x5，deconv用9x9</li>
<li>激活函数用PReLU，据说不会导致dead kernel</li>
<li>每层的权重初始化采用不同的mean和stdev，weight和bias采用不同的learning rate</li>
<li>只采用了MSE作为loss函数，目前state-of-the-art是perceptual loss以及adverserial loss</li>
</ol>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><a target="_blank" rel="noopener" href="https://ws3.sinaimg.cn/large/006tKfTcgy1g0ehush4tmj31260bgadw.jpg"><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1g0ehush4tmj31260bgadw.jpg" alt="result"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>将convNet应用到超像素任务，并且非常快，结构非常精简，论文简单易懂。</p>
<p>可是源码是陈旧是caffe，重现实验效果花了我1个月（其实是我太渣…）。忽略了源码中各层权重采用了不同的初始化参数，忽略了data需要做patch，忽略了网络是按scale factor = 3训练后再fintune到其他scale factor的。</p>
<p>曾经是state-of-the-art的超像素网络，但是李飞飞的新论文显示，超像素的效果，不完全是基于psnr判断的，提出一个perceptual loss，替换掉MSE的loss function之后，输出的图片psnr较低，但是感官效果更好。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/SuperResolution%20by%20FSRCNN/" data-id="cktob6buv0004qgtk8m1p1gk2" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-在macOS安装OpenCV以及VScode的设置" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/%E5%9C%A8macOS%E5%AE%89%E8%A3%85OpenCV%E4%BB%A5%E5%8F%8AVScode%E7%9A%84%E8%AE%BE%E7%BD%AE/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:03:49.901Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="在macOS安装OpenCV以及VScode的设置"><a href="#在macOS安装OpenCV以及VScode的设置" class="headerlink" title="在macOS安装OpenCV以及VScode的设置"></a>在macOS安装OpenCV以及VScode的设置</h1><p>总结一下这两天在macOS上装OpenCV的血泪史</p>
<hr>
<h1 id="Requirement"><a href="#Requirement" class="headerlink" title="Requirement"></a>Requirement</h1><ol>
<li>Xcode</li>
<li>VScode</li>
<li><a target="_blank" rel="noopener" href="https://opencv.org/releases.html">OpenCV官网</a>下载最新版source file</li>
<li>brew install cmake</li>
</ol>
<h1 id="编译OpenCV的source-file"><a href="#编译OpenCV的source-file" class="headerlink" title="编译OpenCV的source file"></a>编译OpenCV的source file</h1><p>cd到<code>opencv-4.0.1</code>文件夹下（目前最新版是4.0.1）</p>
<p><code>mkdir build</code>用于存放后面生成的文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd build </span><br><span class="line">cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local .. #会生成一堆文件在build文件夹以及/usr/local文件夹</span><br><span class="line">make # compile</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<p>这时候OpenCV已经安装好了</p>
<h1 id="VScode配置"><a href="#VScode配置" class="headerlink" title="VScode配置"></a>VScode配置</h1><p>Demo cpp如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;opencv2/opencv.hpp&gt;</span><br><span class="line">#include &lt;chrono&gt;</span><br><span class="line">#include &lt;thread&gt;</span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">int main(int argc, char** argv )</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;HEllo World!\n&quot;);</span><br><span class="line">    if ( argc != 2 )</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot;usage: DisplayImage.out &lt;Image_Path&gt;\n&quot;);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;%s\n&quot;, argv[1]);</span><br><span class="line">    Mat image = imread( argv[1], 1 );</span><br><span class="line">    if ( !image.data )</span><br><span class="line">    &#123;</span><br><span class="line">        printf(&quot;No image data \n&quot;);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line">    namedWindow(&quot;Display Image&quot;, WINDOW_AUTOSIZE );</span><br><span class="line">    imshow(&quot;Display Image&quot;, image);</span><br><span class="line">    waitKey(0);</span><br><span class="line">    std::this_thread::sleep_for(std::chrono::milliseconds(10000));</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>配置c_cpp_properties.json：增加opencv安装位置的路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&quot;includePath&quot;: [</span><br><span class="line">                &quot;$&#123;workspaceFolder&#125;/**&quot;,</span><br><span class="line">                &quot;/usr/local/include/opencv4&quot;</span><br><span class="line">            ]</span><br></pre></td></tr></table></figure>

<p>这时候code里面就可以用opencv的代码提示了</p>
<h1 id="用cmake-compile程序"><a href="#用cmake-compile程序" class="headerlink" title="用cmake compile程序"></a>用cmake compile程序</h1><p>在main.cpp所在目录新建一个文件<code>CMakeLists.txt</code>，指定编译时需要用的库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 3.13.4)</span><br><span class="line">set(CMAKE_CXX_STANDARD 11) //c++标准 cv4需要c11</span><br><span class="line">set(CMAKE_CXX_STANDARD_REQUIRED ON)</span><br><span class="line">project( CV ) //自定义project名称为CV</span><br><span class="line">find_package( OpenCV REQUIRED ) //搜索opencv库</span><br><span class="line">include_directories( $&#123;OpenCV_INCLUDE_DIRS&#125; ) //include opencv</span><br><span class="line">add_executable( CV main.cpp ) //生成的可执行命令，自定义为CV</span><br><span class="line">target_link_libraries( CV $&#123;OpenCV_LIBS&#125; )</span><br></pre></td></tr></table></figure>

<p>然后</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir build #可自定义</span><br><span class="line">cd build</span><br><span class="line">cmake ..</span><br></pre></td></tr></table></figure>

<p>这时候已经vscode全部配置好了</p>
<h1 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h1><p>cpp代码写好之后，在<code>build</code>文件夹里面执行<code>make</code>就会编译cpp文件了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-- Configuring done</span><br><span class="line">-- Generating done</span><br><span class="line">-- Build files have been written to: /Users/T5eng/Desktop/CV/build</span><br><span class="line">Scanning dependencies of target CV</span><br><span class="line">[ 50%] Building CXX object CMakeFiles/CV.dir/main.cpp.o</span><br><span class="line">[100%] Linking CXX executable CV</span><br><span class="line">[100%] Built target CV</span><br></pre></td></tr></table></figure>

<p>这时候会生成一个可执行命令CV</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./CV &lt;image-path&gt;</span><br></pre></td></tr></table></figure>

<p>如无意外，会输出一个hello world同时显示图片。</p>
<h1 id="大功告成"><a href="#大功告成" class="headerlink" title="大功告成"></a>大功告成</h1>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/%E5%9C%A8macOS%E5%AE%89%E8%A3%85OpenCV%E4%BB%A5%E5%8F%8AVScode%E7%9A%84%E8%AE%BE%E7%BD%AE/" data-id="cktob6bv0000aqgtkdo6ve0zt" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-tfRecord 搬运" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/tfRecord%20%E6%90%AC%E8%BF%90/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:03:26.346Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="tfRecord-搬运"><a href="#tfRecord-搬运" class="headerlink" title="tfRecord 搬运"></a>tfRecord 搬运</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>最新上传的<a target="_blank" rel="noopener" href="https://github.com/ycszen/TensorFlowLaboratory/tree/master/mcnn">mcnn</a>中有完整的数据读写示例，可以参考。</p>
<p>关于Tensorflow读取数据，官网给出了三种方法：</p>
<p>**供给数据(Feeding)**： 在TensorFlow程序运行的每一步， 让Python代码来供给数据。</p>
<p><strong>从文件读取数据</strong>： 在TensorFlow图的起始， 让一个输入管线从文件中读取数据。</p>
<p><strong>预加载数据</strong>： 在TensorFlow图中定义常量或变量来保存所有数据(仅适用于数据量比较小的情况)。</p>
<p>对于数据量较小而言，可能一般选择直接将数据加载进内存，然后再分<code>batch</code>输入网络进行训练（tip:使用这种方法时，结合<code>yield</code> 使用更为简洁，大家自己尝试一下吧，我就不赘述了）。但是，如果数据量较大，这样的方法就不适用了，因为太耗内存，所以这时最好使用tensorflow提供的队列<code>queue</code>，也就是第二种方法 从文件读取数据。对于一些特定的读取，比如csv文件格式，官网有相关的描述，在这儿我介绍一种比较通用，高效的读取方法（官网介绍的少），即使用tensorflow内定标准格式——<code>TFRecords</code></p>
<p>太长不看，直接看源码请猛戳我的<a target="_blank" rel="noopener" href="https://github.com/ycszen/tf_lab/blob/master/reading_data/example_tfrecords.py">github</a>，记得加星哦。</p>
<h2 id="TFRecords"><a href="#TFRecords" class="headerlink" title="TFRecords"></a>TFRecords</h2><p>TFRecords其实是一种二进制文件，虽然它不如其他格式好理解，但是它能更好的利用内存，更方便复制和移动，并且不需要单独的标签文件（等会儿就知道为什么了）… …总而言之，这样的文件格式好处多多，所以让我们用起来吧。</p>
<p>TFRecords文件包含了<code>tf.train.Example</code> 协议内存块(protocol buffer)(协议内存块包含了字段 <code>Features</code>)。我们可以写一段代码获取你的数据， 将数据填入到<code>Example</code>协议内存块(protocol buffer)，将协议内存块序列化为一个字符串， 并且通过<code>tf.python_io.TFRecordWriter</code> 写入到TFRecords文件。</p>
<p>从TFRecords文件中读取数据， 可以使用<code>tf.TFRecordReader</code>的<code>tf.parse_single_example</code>解析器。这个操作可以将<code>Example</code>协议内存块(protocol buffer)解析为张量。</p>
<p>接下来，让我们开始读取数据之旅吧~</p>
<h2 id="生成TFRecords文件"><a href="#生成TFRecords文件" class="headerlink" title="生成TFRecords文件"></a>生成TFRecords文件</h2><p>我们使用<code>tf.train.Example</code>来定义我们要填入的数据格式，然后使用<code>tf.python_io.TFRecordWriter</code>来写入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">cwd = os.getcwd()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">此处我加载的数据目录如下：</span></span><br><span class="line"><span class="string">0 -- img1.jpg</span></span><br><span class="line"><span class="string">     img2.jpg</span></span><br><span class="line"><span class="string">     img3.jpg</span></span><br><span class="line"><span class="string">     ...</span></span><br><span class="line"><span class="string">1 -- img1.jpg</span></span><br><span class="line"><span class="string">     img2.jpg</span></span><br><span class="line"><span class="string">     ...</span></span><br><span class="line"><span class="string">2 -- ...</span></span><br><span class="line"><span class="string"> 这里的0， 1， 2...就是类别，也就是下文中的classes</span></span><br><span class="line"><span class="string"> classes是我根据自己数据类型定义的一个列表，大家可以根据自己的数据情况灵活运用</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">writer = tf.python_io.TFRecordWriter(<span class="string">&quot;train.tfrecords&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> index, name <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes):</span><br><span class="line">    class_path = cwd + name + <span class="string">&quot;/&quot;</span></span><br><span class="line">    <span class="keyword">for</span> img_name <span class="keyword">in</span> os.listdir(class_path):</span><br><span class="line">        img_path = class_path + img_name</span><br><span class="line">            img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">            img = img.resize((<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">        img_raw = img.tobytes()              <span class="comment">#将图片转化为原生bytes</span></span><br><span class="line">        example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">            <span class="string">&quot;label&quot;</span>: tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),</span><br><span class="line">            <span class="string">&#x27;img_raw&#x27;</span>: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))</span><br><span class="line">        &#125;))</span><br><span class="line">        writer.write(example.SerializeToString())  <span class="comment">#序列化为字符串</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>关于<code>Example Feature</code>的相关定义和详细内容，我推荐去官网查看相关API。</p>
<p>基本的，一个<code>Example</code>中包含<code>Features</code>，<code>Features</code>里包含<code>Feature</code>（这里没s）的字典。最后，<code>Feature</code>里包含有一个 <code>FloatList</code>， 或者<code>ByteList</code>，或者<code>Int64List</code></p>
<p>就这样，我们把相关的信息都存到了一个文件中，所以前面才说不用单独的label文件。而且读取也很方便。</p>
<p>接下来是一个简单的读取小例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> serialized_example <span class="keyword">in</span> tf.python_io.tf_record_iterator(<span class="string">&quot;train.tfrecords&quot;</span>):</span><br><span class="line">    example = tf.train.Example()</span><br><span class="line">    example.ParseFromString(serialized_example)</span><br><span class="line"></span><br><span class="line">    image = example.features.feature[<span class="string">&#x27;image&#x27;</span>].bytes_list.value</span><br><span class="line">    label = example.features.feature[<span class="string">&#x27;label&#x27;</span>].int64_list.value</span><br><span class="line">    <span class="comment"># 可以做一些预处理之类的</span></span><br><span class="line">    <span class="built_in">print</span> image, label</span><br></pre></td></tr></table></figure>



<h2 id="使用队列读取"><a href="#使用队列读取" class="headerlink" title="使用队列读取"></a>使用队列读取</h2><p>一旦生成了TFRecords文件，为了高效地读取数据，TF中使用队列（<code>queue</code>）读取数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_and_decode</span>(<span class="params">filename</span>):</span></span><br><span class="line">    <span class="comment">#根据文件名生成一个队列</span></span><br><span class="line">    filename_queue = tf.train.string_input_producer([filename])</span><br><span class="line"></span><br><span class="line">    reader = tf.TFRecordReader()</span><br><span class="line">    _, serialized_example = reader.read(filename_queue)   <span class="comment">#返回文件名和文件</span></span><br><span class="line">    features = tf.parse_single_example(serialized_example,</span><br><span class="line">                                       features=&#123;</span><br><span class="line">                                           <span class="string">&#x27;label&#x27;</span>: tf.FixedLenFeature([], tf.int64),</span><br><span class="line">                                           <span class="string">&#x27;img_raw&#x27;</span> : tf.FixedLenFeature([], tf.string),</span><br><span class="line">                                       &#125;)</span><br><span class="line">    </span><br><span class="line">    img = tf.decode_raw(features[<span class="string">&#x27;img_raw&#x27;</span>], tf.uint8)</span><br><span class="line">    img = tf.reshape(img, [<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>])</span><br><span class="line">    img = tf.cast(img, tf.float32) * (<span class="number">1.</span> / <span class="number">255</span>) - <span class="number">0.5</span></span><br><span class="line">    label = tf.cast(features[<span class="string">&#x27;label&#x27;</span>], tf.int32)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> img, label</span><br></pre></td></tr></table></figure>



<p>之后我们可以在训练的时候这样使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">img, label = read_and_decode(<span class="string">&quot;train.tfrecords&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用shuffle_batch可以随机打乱输入</span></span><br><span class="line">img_batch, label_batch = tf.train.shuffle_batch([img, label],</span><br><span class="line">                                                batch_size=<span class="number">30</span>, capacity=<span class="number">2000</span>,</span><br><span class="line">                                                min_after_dequeue=<span class="number">1000</span>)</span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    threads = tf.train.start_queue_runners(sess=sess)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        val, l= sess.run([img_batch, label_batch])</span><br><span class="line">        <span class="comment">#我们也可以根据需要对val， l进行处理</span></span><br><span class="line">        <span class="comment">#l = to_categorical(l, 12) </span></span><br><span class="line">        <span class="built_in">print</span>(val.shape, l)</span><br></pre></td></tr></table></figure>



<p>至此，tensorflow高效从文件读取数据差不多完结了。</p>
<p>恩？等等…什么叫差不多？对了，还有几个注意事项：</p>
<p>第一，tensorflow里的graph能够记住状态（<code>state</code>），这使得<code>TFRecordReader</code>能够记住tfrecord的位置，并且始终能返回下一个。而这就要求我们在使用之前，必须初始化整个graph，这里我们使用了函数<code>tf.initialize_all_variables()</code>来进行初始化。</p>
<p>第二，tensorflow中的队列和普通的队列差不多，不过它里面的<code>operation</code>和<code>tensor</code>都是符号型的（<code>symbolic</code>），在调用<code>sess.run()</code>时才执行。</p>
<p>第三， <code>TFRecordReader</code>会一直弹出队列中文件的名字，直到队列为空。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>生成tfrecord文件</li>
<li>定义<code>record reader</code>解析tfrecord文件</li>
<li>构造一个批生成器（<code>batcher</code>）</li>
<li>构建其他的操作</li>
<li>初始化所有的操作</li>
<li>启动<code>QueueRunner</code></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/tfRecord%20%E6%90%AC%E8%BF%90/" data-id="cktob6buy0008qgtk15lwh3m1" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-PyTorch 常用api (不定期更新)" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/PyTorch%20%E5%B8%B8%E7%94%A8api%20(%E4%B8%8D%E5%AE%9A%E6%9C%9F%E6%9B%B4%E6%96%B0)/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:03:05.559Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="PyTorch-常用api-不定期更新"><a href="#PyTorch-常用api-不定期更新" class="headerlink" title="PyTorch 常用api (不定期更新)"></a>PyTorch 常用api (不定期更新)</h1><h1 id="Checkpoint-amp-Loading"><a href="#Checkpoint-amp-Loading" class="headerlink" title="Checkpoint &amp; Loading"></a>Checkpoint &amp; Loading</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存和加载整个模型 </span></span><br><span class="line">torch.save(model_object, <span class="string">&#x27;model.pkl&#x27;</span>) </span><br><span class="line">model = torch.load(<span class="string">&#x27;model.pkl&#x27;</span>)</span><br><span class="line"><span class="comment"># 仅保存和加载模型参数(推荐使用) </span></span><br><span class="line">torch.save(model_object.state_dict(), <span class="string">&#x27;params.pkl&#x27;</span>) </span><br><span class="line">model_object.load_state_dict(torch.load(<span class="string">&#x27;params.pkl&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h1 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h1><p>参数的初始化其实就是对参数赋值。而我们需要学习的参数其实都是Variable，它其实是对Tensor的封装，同时提供了data，grad等接口，这就意味着我们可以直接对这些参数进行操作赋值了。这就是PyTorch简洁高效所在。</p>
<p>所以我们可以进行如下操作进行初始化，当然其实有其他的方法，但是这种方法是PyTorch作者所推崇的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_init</span>(<span class="params">m</span>):</span></span><br><span class="line"><span class="comment"># 使用isinstance来判断m属于什么类型</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">        n = m.kernel_size[<span class="number">0</span>] * m.kernel_size[<span class="number">1</span>] * m.out_channels</span><br><span class="line">        m.weight.data.normal_(<span class="number">0</span>, math.sqrt(<span class="number">2.</span> / n))</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line"><span class="comment"># m中的weight，bias其实都是Variable，为了能学习参数以及后向传播</span></span><br><span class="line">        m.weight.data.fill_(<span class="number">1</span>)</span><br><span class="line">        m.bias.data.zero_()</span><br></pre></td></tr></table></figure>

<p>另一种常见的初始化方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nn.init.kaiming_normal(self.W.weight)</span><br><span class="line">nn.init.constant(self.W[<span class="number">0</span>].bias, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="局部微调"><a href="#局部微调" class="headerlink" title="局部微调"></a>局部微调</h2><p>有时候我们加载了训练模型后，只想调节最后的几层，其他层不训练。其实不训练也就意味着不进行梯度计算，PyTorch中提供的requires_grad使得对训练的控制变得非常简单。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 替换最后的全连接层， 改为训练100类</span></span><br><span class="line"><span class="comment"># 新构造的模块的参数默认requires_grad为True</span></span><br><span class="line">model.fc = nn.Linear(<span class="number">512</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只优化最后的分类层</span></span><br><span class="line">optimizer = optim.SGD(model.fc.parameters(), lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>

<h2 id="全局微调"><a href="#全局微调" class="headerlink" title="全局微调"></a>全局微调</h2><p>有时候我们需要对全局都进行finetune，只不过我们希望改换过的层和其他层的学习速率不一样，这时候我们可以把其他层和新层在optimizer中单独赋予不同的学习速率。比如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ignored_params = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">id</span>, model.fc.parameters()))</span><br><span class="line">base_params = <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: <span class="built_in">id</span>(p) <span class="keyword">not</span> <span class="keyword">in</span> ignored_params,</span><br><span class="line">                     model.parameters())</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD([</span><br><span class="line">            &#123;<span class="string">&#x27;params&#x27;</span>: base_params&#125;,</span><br><span class="line">            &#123;<span class="string">&#x27;params&#x27;</span>: model.fc.parameters(), <span class="string">&#x27;lr&#x27;</span>: <span class="number">1e-2</span>&#125;</span><br><span class="line">            ], lr=<span class="number">1e-3</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>

<p>其中base_params使用1e-3来训练，model.fc.parameters使用1e-2来训练，momentum是二者共有的。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/PyTorch%20%E5%B8%B8%E7%94%A8api%20(%E4%B8%8D%E5%AE%9A%E6%9C%9F%E6%9B%B4%E6%96%B0)/" data-id="cktob6buv0003qgtkcfhf5ior" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-NonLocal Neural Network备忘" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/NonLocal%20Neural%20Network%E5%A4%87%E5%BF%98/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:02:47.413Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="NonLocal-Neural-Network备忘"><a href="#NonLocal-Neural-Network备忘" class="headerlink" title="NonLocal Neural Network备忘"></a>NonLocal Neural Network备忘</h1><h2 id="论文简介"><a href="#论文简介" class="headerlink" title="论文简介"></a>论文简介</h2><p>论文由NonLocal mean启发，每个位置的response（响应？）是由全局的权重值求和相关的。NonLocal block设计为可以插入到已有网络结构层与层之间的形式。在视频分类中表现优秀。</p>
<h2 id="intro"><a href="#intro" class="headerlink" title="intro"></a>intro</h2><p>对于序列数据（语音），long distance dependency是建立在递归操作上（如LSTM）；对于图像，long distance dependency是建立在由多层卷积操作建立的大感受域上的。</p>
<p>卷积和递归都是基于当前邻域，实现long distance dependency必须反复遍历数据。计算方式低效，训练困难，信息不容易实现双向传递。</p>
<p>跟self-attention有点关系，每个局部的输出都考虑了全局的加权平均值（self-attention是在embedding空间中计算的，该论文提出的Transformer模型革了RNN的命）。</p>
<p>我们的网络表现很牛，而且可以作为一个基础模块，插入到已有网络中。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4uh90.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4uh90.jpg" alt="image-20190114133153895"></a></p>
<p><strong>yi</strong>为NonLocal mean输出</p>
<p><strong>i</strong>为当前计算点index</p>
<p><strong>j</strong>为全局所有计算点index</p>
<p>**f(xi,xj)**计算2点之间相似程度（paper提供了4种方式：Gaussian, Embedded Gaussian, Dot Product, Concatenation)</p>
<p>**g(xj)**为j点的response值</p>
<p>C(x)为归一化值，取值为sum_j {f(xi,xj)}</p>
<h2 id="NonLocal-Block"><a href="#NonLocal-Block" class="headerlink" title="NonLocal Block"></a>NonLocal Block</h2><p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4uWhq.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4uWhq.jpg" alt="image-20190114133936809"></a></p>
<p><strong>yi</strong>为NonLocal mean输出</p>
<p><strong>Wz</strong>为NL层的可训练权重</p>
<p><strong>xi</strong>作为残差连接，将Wz初始化为0时，则可以插入到已有模型中且不影响模型结果。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>基于ResNet50的Conv2D和Inflate3D版本，对比插入1、5、10个NonLocal Block之后的表现。</p>
<p>C2D可以直接用ResNet50的预训练权重；I3D可以将卷积核的每片都用2D的版本初始化然后除以t（t为inflate的倍数）</p>
<p>因为Inflate3D计算量比较大，因此每2个resBlock才inflate一个。</p>
<h2 id="Trick"><a href="#Trick" class="headerlink" title="Trick"></a>Trick</h2><p>采用Embedded Gaussian计算NonLocal Mean时通道数选为输入通道的一半，再加一层pooling可以进一步降低计算量到1/4</p>
<p>数据画面随机剪裁，从连续的64帧中随机截选<strong>32帧</strong>作为一组</p>
<p>8GPU，每个GPU计算8组，相当于一个mini-batch有62组数据</p>
<p>训练400k轮，lr=0.01，每150k减少一个数量级</p>
<p>opt用momentum=0.9，weight decay=0.0001，在最后的global pooling layer用0.5的dropout</p>
<p>在每个NonLocal Block的最后一层1x1x1中使用BatchNorm，并且该层权重初始化为0，保证可以插入到任意已训练的网络结构中</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4u5cT.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4u5cT.jpg" alt="image-20190114143358883"></a></p>
<p>4种NonLocal Weight计算方法效果接近。</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4uTuF.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4uTuF.jpg" alt="image-20190114143420341"></a></p>
<p>将1个NonLocal Block加到不同位置，效果接近</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4u43V.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4u43V.jpg" alt="image-20190114143455820"></a></p>
<p>更深的网络也可以用NonLocal Block进一步提高表现（ResNet101）</p>
<p>NonLocal的提升也不仅仅是因为深度增加了（R50 + 5-block &gt; R101 base）</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4uqE9.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4uqE9.jpg" alt="image-20190114143622712"></a></p>
<p>NonLocal考虑space&amp;time时效果最好（计算量更大？）</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4uIjU.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4uIjU.jpg" alt="image-20190114143709720"></a></p>
<p>对比I3D，减少了计算量，提高了效果</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4u7B4.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4u7B4.jpg" alt="image-20190115221557322"></a></p>
<p>对比C2D、Inflate3D和NonLocal Inflate3D的表现。NonLocal可以与conv3D互补，得到更好表现</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4uHHJ.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4uHHJ.jpg" alt="image-20190115220819622"></a></p>
<p>用128帧一组数据，效果更好（计算量翻4倍？）基于32帧的训练模型进行训练，lr=0.0025。在更长的数据中，NLI3D相比I3D也仍然有提升。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/NonLocal%20Neural%20Network%E5%A4%87%E5%BF%98/" data-id="cktob6buu0002qgtk1aj1e3r3" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-ML 入门：归一化、标准化和正则化" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/ML%20%E5%85%A5%E9%97%A8%EF%BC%9A%E5%BD%92%E4%B8%80%E5%8C%96%E3%80%81%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:02:27.164Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="ML-入门：归一化、标准化和正则化"><a href="#ML-入门：归一化、标准化和正则化" class="headerlink" title="ML 入门：归一化、标准化和正则化"></a>ML 入门：归一化、标准化和正则化</h1><p>因为经常混淆Normalization和Regularization两个名词，所以搬运了一篇文章。原文：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29957294">https://zhuanlan.zhihu.com/p/29957294</a></p>
<h2 id="0x01-归一化-Normalization"><a href="#0x01-归一化-Normalization" class="headerlink" title="0x01 归一化 Normalization"></a><strong>0x01 归一化 Normalization</strong></h2><p>归一化一般是将数据映射到指定的范围，用于去除不同维度数据的量纲以及量纲单位。</p>
<p>常见的映射范围有 [0, 1] 和 [-1, 1] ，最常见的归一化方法就是 <strong>Min-Max 归一化</strong>：</p>
<h2 id="Min-Max-归一化"><a href="#Min-Max-归一化" class="headerlink" title="Min-Max 归一化"></a><strong>Min-Max 归一化</strong></h2><p><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=x_%7Bnew%7D=%5Cfrac%7Bx-x_%7Bmin%7D%7D%7Bx_%7Bmax%7D-x_%7Bmin%7D%7D"><img src="http://www.zhihu.com/equation?tex=x_%7Bnew%7D=%5Cfrac%7Bx-x_%7Bmin%7D%7D%7Bx_%7Bmax%7D-x_%7Bmin%7D%7D" alt="x_{new}=\frac{x-x_{min}}{x_{max}-x_{min}}"></a></p>
<p>举个例子，我们判断一个人的身体状况是否健康，那么我们会采集人体的很多指标，比如说：身高、体重、红细胞数量、白细胞数量等。</p>
<p>一个人身高 180cm，体重 70kg，白细胞计数<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=7.50%C3%9710%5E%7B9%7D/L"><img src="http://www.zhihu.com/equation?tex=7.50%C3%9710%5E%7B9%7D/L" alt="7.50×10^{9}/L"></a>，etc.</p>
<p>衡量两个人的状况时，白细胞计数就会起到主导作用从而<strong>遮盖住其他的特征</strong>，归一化后就不会有这样的问题。</p>
<h2 id="0x02-标准化-Normalization"><a href="#0x02-标准化-Normalization" class="headerlink" title="0x02 标准化 Normalization"></a><strong>0x02 标准化 Normalization</strong></h2><p><strong>在这里我们需要强调一下英文翻译的问题，在 Udacity 字幕组中对此进行了探讨：</strong></p>
<blockquote>
<p>归一化和标准化的英文翻译是一致的，但是根据其用途（或公式）的不同去理解（或翻译）</p>
</blockquote>
<p>下面我们将探讨最常见的标准化方法： <strong>Z-Score 标准化</strong>。</p>
<h2 id="Z-Score-标准化"><a href="#Z-Score-标准化" class="headerlink" title="Z-Score 标准化"></a><strong>Z-Score 标准化</strong></h2><p><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=x_%7Bnew%7D=%5Cfrac%7Bx-%5Cmu+%7D%7B%5Csigma+%7D"><img src="http://www.zhihu.com/equation?tex=x_%7Bnew%7D=%5Cfrac%7Bx-%5Cmu+%7D%7B%5Csigma+%7D" alt="x_{new}=\frac{x-\mu }{\sigma }"></a></p>
<p>其中<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%5Cmu"><img src="http://www.zhihu.com/equation?tex=%5Cmu" alt="\mu"></a>是样本数据的<strong>均值（mean）</strong>，<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%5Csigma"><img src="http://www.zhihu.com/equation?tex=%5Csigma" alt="\sigma"></a>是样本数据的<strong>标准差（std）</strong>。</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4K9De.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4K9De.jpg" alt="img"></a></p>
<p>上图则是一个散点序列的标准化过程：原图-&gt;减去均值-&gt;除以标准差。</p>
<p>显而易见，变成了一个<strong>均值为 0 ，方差为 1 的分布</strong>，下图通过 Cost 函数让我们更好的理解标准化的作用。</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4KiEd.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4KiEd.jpg" alt="img"></a></p>
<p>机器学习的目标无非就是不断优化损失函数，使其值最小。在上图中，<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=J(w,b)"><img src="http://www.zhihu.com/equation?tex=J(w,b)" alt="J(w,b)"></a>就是我们要优化的目标函数</p>
<p>我们不难看出，<strong>标准化后可以更加容易地得出最优参数</strong><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=w"><img src="http://www.zhihu.com/equation?tex=w" alt="w"></a><strong>和</strong><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=b"><img src="http://www.zhihu.com/equation?tex=b" alt="b"></a><strong>以及计算出</strong><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=J(w,b)"><img src="http://www.zhihu.com/equation?tex=J(w,b)" alt="J(w,b)"></a><strong>的最小值，从而达到加速收敛的效果</strong>。[<img src="http://www.zhihu.com/equation?tex=%5E%7B%5B1%5D%7D" alt="^{[1]}](http://www.zhihu.com/equation?tex=%5E%7B%5B1%5D%7D)"></p>
<p><em>注：上图来源于 Andrew Ng 的课程讲义</em></p>
<h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a><strong>Batch Normalization</strong></h2><p>在机器学习中，<strong>最常用标准化的地方</strong>莫过于神经网络的 <strong>BN 层（Batch Normalization）</strong>，因此我们简单的谈谈 BN 层的原理和作用，想要更深入的了解可以<a href="http://link.zhihu.com/?target=https://arxiv.org/abs/1502.03167">查看论文</a>。</p>
<p>我们知道数据预处理做标准化可以加速收敛，同理，在神经网络使用标准化也可以<strong>加速收敛</strong>，而且还有如下好处：</p>
<ul>
<li>具有正则化的效果（Batch Normalization reglarizes the model）</li>
<li>提高模型的泛化能力（Be advantageous to the generalization of network）</li>
<li>允许更高的学习速率从而加速收敛（Batch Normalization enables higher learning rates）</li>
</ul>
<p>其原理是<strong>利用正则化减少内部相关变量分布的偏移（Reducing Internal Covariate Shift）</strong>，从而<strong>提高了算法的鲁棒性</strong>。[<img src="http://www.zhihu.com/equation?tex=%5E%7B%5B2%5D%7D" alt="^{[2]}](http://www.zhihu.com/equation?tex=%5E%7B%5B2%5D%7D)"></p>
<p>Batch Normalization 由两部分组成，第一部分是<strong>缩放与平移（scale and shift）</strong>，第二部分是<strong>训练缩放尺度和平移的参数（train a BN Network）</strong>，算法步骤如下：</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4KCHH.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4KCHH.jpg" alt="img"></a></p>
<p>接下来训练 BN 层参数<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%5Cgamma"><img src="http://www.zhihu.com/equation?tex=%5Cgamma" alt="\gamma"></a>和<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%5Cbeta+"><img src="http://www.zhihu.com/equation?tex=%5Cbeta+" alt="\beta "></a>，限于篇幅的原因按下不表，有兴趣的读者可以拜读<a href="http://link.zhihu.com/?target=https://arxiv.org/abs/1502.03167">这篇论文</a>。</p>
<h2 id="0x03-正则化-Regularization"><a href="#0x03-正则化-Regularization" class="headerlink" title="0x03 正则化 Regularization"></a><strong>0x03 正则化 Regularization</strong></h2><p><strong>正则化主要用于避免过拟合的产生和减少网络误差。</strong></p>
<p>正则化一般具有如下形式：</p>
<p><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=J(w,b)=+%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi=1%7D%5E%7Bm%7DL(f(x),y)+%5Clambda+R(f)"><img src="http://www.zhihu.com/equation?tex=J(w,b)=+%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi=1%7D%5E%7Bm%7DL(f(x),y)+%5Clambda+R(f)" alt="J(http://www.zhihu.com/equation?tex=J%28w%2Cb%29%3D+%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi%3D1%7D%5E%7Bm%7DL%28f%28x%29%2Cy%29%2B%5Clambda+R%28f%29)= \frac{1}{m} \sum_{i=1}^{m}L(f(x),y)+\lambda R(f)"></a></p>
<p>其中，第 1 项是<strong>经验风险</strong>，第 2 项是<strong>正则项</strong>，<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%CE%BB%E2%89%A50"><img src="http://www.zhihu.com/equation?tex=%CE%BB%E2%89%A50" alt="λ≥0"></a>为调整两者之间关系的系数。</p>
<p>第 1 项的经验风险较小的模型可能较复杂（有多个非零参数），这时第 2 项的模型复杂度会较大。</p>
<p>常见的有正则项有 <strong>L1 正则</strong> 和 <strong>L2 正则</strong> ，其中 <strong>L2 正则</strong> 的控制过拟合的效果比 <strong>L1 正则</strong> 的好。</p>
<p><strong>正则化的作用是选择经验风险与模型复杂度同时较小的模型</strong>。[<img src="http://www.zhihu.com/equation?tex=%5E%7B%5B3%5D%7D" alt="^{[3]}](http://www.zhihu.com/equation?tex=%5E%7B%5B3%5D%7D)"></p>
<p>常见的有正则项有 <strong>L1 正则</strong> 和 <strong>L2 正则</strong> 以及 <strong>Dropout</strong> ，其中 <strong>L2 正则</strong> 的控制过拟合的效果比 <strong>L1 正则</strong> 的好。</p>
<h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=L_%7Bp%7D"><img src="http://www.zhihu.com/equation?tex=L_%7Bp%7D" alt="L_{p}"></a><strong>范数</strong></h2><p>为什么叫 L1 正则，有 L1、L2 正则 那么有没有 L3、L4 之类的呢？</p>
<p>首先我们补一补课，<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=L_%7Bp%7D"><img src="http://www.zhihu.com/equation?tex=L_%7Bp%7D" alt="L_{p}"></a>正则的 L 是指<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=L_%7Bp%7D"><img src="http://www.zhihu.com/equation?tex=L_%7Bp%7D" alt="L_{p}"></a>范数，其定义为：</p>
<p><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=L_%7B0%7D"><img src="http://www.zhihu.com/equation?tex=L_%7B0%7D" alt="L_{0}"></a>范数：<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%5Cleft+%7C+w+%5Cright+%7C_%7B0%7D+=+%23(i)+with++x_%7Bi%7D+%5Cneq+0"><img src="http://www.zhihu.com/equation?tex=%5Cleft+%5C%7C+w+%5Cright+%5C%7C_%7B0%7D+=+%5C%23(i)%5C+with+%5C+x_%7Bi%7D+%5Cneq+0" alt="\left \| w \right \|_{0} = \#(i)\ with \ x_{i} \neq 0"></a><em>（非零元素的个数）</em></p>
<p><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=L_%7B1%7D"><img src="http://www.zhihu.com/equation?tex=L_%7B1%7D" alt="L_{1}"></a>范数：<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%5Cleft+%7C+w+%5Cright+%7C_%7B1%7D+=+%5Csum_%7Bi+=+1%7D%5E%7Bd%7D%5Clvert+x_i%5Crvert"><img src="http://www.zhihu.com/equation?tex=%5Cleft+%5C%7C+w+%5Cright+%5C%7C_%7B1%7D+=+%5Csum_%7Bi+=+1%7D%5E%7Bd%7D%5Clvert+x_i%5Crvert" alt="\left \| w \right \|_{1} = \sum_{i = 1}^{d}\lvert x_i\rvert"></a><em>（每个元素绝对值之和）</em></p>
<p><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=L_%7B2%7D"><img src="http://www.zhihu.com/equation?tex=L_%7B2%7D" alt="L_{2}"></a>范数：<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%5Cleft+%7C+w+%5Cright+%7C_%7B2%7D+=+%5CBigl(%5Csum_%7Bi+=+1%7D%5E%7Bd%7D+x_i%5E2%5CBigr)%5E%7B1/2%7D"><img src="http://www.zhihu.com/equation?tex=%5Cleft+%5C%7C+w+%5Cright+%5C%7C_%7B2%7D+=+%5CBigl(%5Csum_%7Bi+=+1%7D%5E%7Bd%7D+x_i%5E2%5CBigr)%5E%7B1/2%7D" alt="\left \| w \right \|_{2} = \Bigl(\sum_{i = 1}^{d} x_i^2\Bigr)^{1/2}"></a><em>（欧氏距离）</em></p>
<p><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=L_%7Bp%7D"><img src="http://www.zhihu.com/equation?tex=L_%7Bp%7D" alt="L_{p}"></a>范数：<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%5Cleft+%7C+w+%5Cright+%7C_%7Bp%7D+=+%5CBigl(%5Csum_%7Bi+=+1%7D%5E%7Bd%7D+x_i%5Ep%5CBigr)%5E%7B1/p%7D"><img src="http://www.zhihu.com/equation?tex=%5Cleft+%5C%7C+w+%5Cright+%5C%7C_%7Bp%7D+=+%5CBigl(%5Csum_%7Bi+=+1%7D%5E%7Bd%7D+x_i%5Ep%5CBigr)%5E%7B1/p%7D" alt="\left \| w \right \|_{p} = \Bigl(\sum_{i = 1}^{d} x_i^p\Bigr)^{1/p}"></a></p>
<p>在机器学习中，若使用了<a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=%5ClVert+w%5CrVert_p"><img src="http://www.zhihu.com/equation?tex=%5ClVert+w%5CrVert_p" alt="\lVert w\rVert_p"></a>作为正则项，我们则说该机器学习任务<strong>引入了</strong><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=L_%7Bp%7D"><img src="http://www.zhihu.com/equation?tex=L_%7Bp%7D" alt="L_{p}"></a><strong>正则项</strong>。</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4KFUA.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4KFUA.jpg" alt="img"></a></p>
<p><em>上图来自周志华老师的《机器学习》插图</em></p>
<h2 id="L1-正则-Lasso-regularizer"><a href="#L1-正则-Lasso-regularizer" class="headerlink" title="L1 正则 Lasso regularizer"></a><strong>L1 正则 Lasso regularizer</strong></h2><p><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=J(w,b)=%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi=1%7D%5E%7Bm%7DL(%5Chat%7By%7D,y)+%5Cfrac%7B%5Clambda+%7D%7Bm%7D%5Cleft+%7C+w+%5Cright+%7C_%7B1%7D"><img src="http://www.zhihu.com/equation?tex=J(w,b)=%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi=1%7D%5E%7Bm%7DL(%5Chat%7By%7D,y)+%5Cfrac%7B%5Clambda+%7D%7Bm%7D%5Cleft+%5C%7C+w+%5Cright+%5C%7C_%7B1%7D" alt="J(w,b)=\frac{1}{m} \sum_{i=1}^{m}L(\hat{y},y)+\frac{\lambda }{m}\left \| w \right \|_{1}"></a></p>
<ul>
<li>凸函数，不是处处可微分</li>
<li>得到的是稀疏解（最优解常出现在顶点上，且顶点上的 w 只有很少的元素是非零的）</li>
</ul>
<h2 id="L2-正则-Ridge-Regularizer-Weight-Decay"><a href="#L2-正则-Ridge-Regularizer-Weight-Decay" class="headerlink" title="L2 正则 Ridge Regularizer / Weight Decay"></a><strong>L2 正则 Ridge Regularizer / Weight Decay</strong></h2><p><a target="_blank" rel="noopener" href="http://www.zhihu.com/equation?tex=J(w,b)=%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi=1%7D%5E%7Bm%7DL(%5Chat%7By%7D,y)+%5Cfrac%7B%5Clambda+%7D%7B2m%7D%5Cleft+%7C+w+%5Cright+%7C%5E%7B2%7D_%7B2%7D"><img src="http://www.zhihu.com/equation?tex=J(w,b)=%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi=1%7D%5E%7Bm%7DL(%5Chat%7By%7D,y)+%5Cfrac%7B%5Clambda+%7D%7B2m%7D%5Cleft+%5C%7C+w+%5Cright+%5C%7C%5E%7B2%7D_%7B2%7D" alt="J(w,b)=\frac{1}{m} \sum_{i=1}^{m}L(\hat{y},y)+\frac{\lambda }{2m}\left \| w \right \|^{2}_{2}"></a></p>
<ul>
<li>凸函数，处处可微分</li>
<li>易于优化</li>
</ul>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a><strong>Dropout</strong></h2><p><strong>Dropout 主要用于神经网络，其原理是使神经网络中的某些神经元随机失活，让模型不过度依赖某一神经元，达到增强模型鲁棒性以及控制过拟合的效果。</strong></p>
<p>除此之外，Dropout 还有多模型投票等功能，若有兴趣可以拜读<a href="http://link.zhihu.com/?target=https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf">这篇论文</a><strong>。</strong></p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4KpuD.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4KpuD.jpg" alt="img"></a></p>
<h2 id="0x04-Reference"><a href="#0x04-Reference" class="headerlink" title="0x04 Reference"></a><strong>0x04 Reference</strong></h2><p>[1] LeCun, Y., Bottou, L., Orr, G., and Muller, K. Efficient backprop. In Orr, G. and K., Muller (eds.), Neural Net-works: Tricks of the trade. Springer, 1998b.</p>
<p>[2] Sergey Ioffe, Christian Szegedy, “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift”, arXiv preprint arXiv:1502.03167, 2015.</p>
<p>[3] 李航. 统计方法学 P13-14</p>
<p>[4] 聊聊机器学习中的损失函数 <a href="http://link.zhihu.com/?target=http://kubicode.me/2016/04/11/Machine%20Learning/Say-About-Loss-Function/">http://kubicode.me/2016/04/11/Machine%20Learning/Say-About-Loss-Function/</a></p>
<p>[5] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever and Ruslan Salakhutdinov, “Dropout: A Simple Way to Prevent Neural Networks from<br>Overfitting”,</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/ML%20%E5%85%A5%E9%97%A8%EF%BC%9A%E5%BD%92%E4%B8%80%E5%8C%96%E3%80%81%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96/" data-id="cktob6bul0000qgtkbydae82m" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-量子计算简述 - intro" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E7%AE%80%E8%BF%B0%20-%20intro/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:01:53.967Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="量子计算简述-intro"><a href="#量子计算简述-intro" class="headerlink" title="量子计算简述 - intro"></a>量子计算简述 - intro</h1><p>以下内容基于课堂理解</p>
<h2 id="量子计算发展史"><a href="#量子计算发展史" class="headerlink" title="量子计算发展史"></a>量子计算发展史</h2><p>1982年，物理学家Feynman提出一个抽象模型，示范利用量子系统做运算。</p>
<p>1985年，牛津大学的Deutsch提出了第一个量子计算机的设计蓝图和网络模型，定义了量子图灵机。</p>
<p>1994年，Shor证明了大数质因子分解的问题，可以用量子计算机快速解决。</p>
<p>1995年，Grover提出在一个无序的数据库中搜索的问题，可以用量子计算机快速解决。</p>
<p>2001年，IBM使用7个量子比特的计算器，用Shor算法实现15分解成3x5.</p>
<p>2018年，IBM实现50量子比特的处理器原型。掌握50量子比特计算机成熟技术的国家将实现“量子霸权”（Quantum Computational Supremacy）。</p>
<h2 id="量子位和量子寄存器"><a href="#量子位和量子寄存器" class="headerlink" title="量子位和量子寄存器"></a>量子位和量子寄存器</h2><p>相较于传统计算机，量子机定义了“<strong>量子位</strong>”（Qubit）。Qubit可以像传统计算机一样处于“0”态或“1”态，也可以处于<strong>叠加态</strong>。在量子力学中用狄拉克符号表示一个Qubit:<br>$$<br>| \psi \rangle = a <em>| 0 \rangle + b</em> | 1 \rangle<br>$$<br>其中：|0&gt;与|1&gt;为<strong>基本态</strong>；a,b为<strong>概率幅</strong>，且有：</p>
<p>|a|2+|b|2=1|a|2+|b|2=1</p>
<p>对于2个Qubit组成的<strong>希尔伯特(Hilbert)空间</strong>，会具有4个基本态，其叠加态为：<br>$$<br>| \psi \rangle = a_{00} <em>|00 \rangle + a_{01}</em> |01 \rangle + a_{10} <em>|10 \rangle + a_{11}</em> |11 \rangle<br>$$<br>其中各参数定义与单Qubit情况类似。</p>
<p>推广到N位Qubit可知，将具有2^n种相互正交的基本态，因此量子寄存器位数的<strong>线性增长</strong>将实现量子寄存器容量的<strong>指数增长</strong>。</p>
<h2 id="量子逻辑门"><a href="#量子逻辑门" class="headerlink" title="量子逻辑门"></a>量子逻辑门</h2><p>个人理解，Qubit的计算可以参考线性代数。</p>
<p>对量子寄存器叠加态进行变换（幺正变换）以实现逻辑功能的操作，称为<strong>量子逻辑门</strong>。</p>
<p>常见的量子逻辑门包括：CNOT门、Hadamard门、Pauli X/Y/Z门、相位门、π/8门、量子旋转门</p>
<p>叠加态的量子比特在多维空间上进行线性变换（量子学称为<strong>幺正变换</strong>）：将叠加态左乘一个<strong>幺正矩阵</strong>（量子逻辑门），可以同时对叠加态中所有Qubit进行变换，因此量子计算具有并行性。即对量子寄存器进行一次幺正变换，相当于传统计算机进行2^n次运算。</p>
<p>而传统计算机由于部分计算是串行的，因此不可能通过无限增加处理器数量达到100%并行。</p>
<h2 id="量子测量与输出"><a href="#量子测量与输出" class="headerlink" title="量子测量与输出"></a>量子测量与输出</h2><p>对叠加态量子体系的测量将造成波函数的坍缩，使叠加态转化为基态。即n位的量子寄存器叠加保存了2^n个二进制数，但输出结果只能为n位的二进制数。</p>
<p>如n=2的情况：<br>$$<br>| \psi \rangle = a_{00} <em>|00 \rangle + a_{01}</em> |01 \rangle + a_{10} <em>|10 \rangle + a_{11}</em> |11 \rangle<br>$$<br>测量后，量子体系将会坍缩到|00&gt;、|01&gt;、|10&gt;、|11&gt;四种状态之一，且坍缩的过程是随机的。因此量子计算的目的就是设计量子算法（通过幺正变换），使所需要的结果的概率尽可能大，不需要的结果的概率尽可能小。</p>
<p>对于多量子体系，各个量子的测量是相对独立的，且符合统计原理的。</p>
<p>例如，对第一个Qubit的测量结果为0的概率为：</p>
<p>P|00⟩+|01⟩=|a00|2+|a01|2P|00⟩+|01⟩=|a00|2+|a01|2</p>
<p>若测量得知第一个Qubit结果为0，此时测量第二个Qubit概率分布应为：</p>
<p>P|00⟩=a00|a00|2+|a01|2</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E7%AE%80%E8%BF%B0%20-%20intro/" data-id="cktob6bv1000cqgtka75g2w1w" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-MobileNet概览" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/09/17/MobileNet%E6%A6%82%E8%A7%88/" class="article-date">
  <time class="dt-published" datetime="2021-09-17T11:00:29.069Z" itemprop="datePublished">2021-09-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="MobileNet概览"><a href="#MobileNet概览" class="headerlink" title="MobileNet概览"></a>MobileNet概览</h1><p>以下内容基于本人阅读理解</p>
<p>arXiv:1704.04861v1 [cs.CV] 17 Apr 2017</p>
<p>arXiv:1801.04381v3 [cs.CV] 2 Apr 2018</p>
<h2 id="论文简介"><a href="#论文简介" class="headerlink" title="论文简介"></a>论文简介</h2><p>谷歌对于目前网络结构为了追求准确率，而不断变深变大，牺牲运算速度的情况不爽。考虑到移动设备和嵌入式设备的运算能力，优化了网络结构，并提出两个超参数width multiplier和resolution multiplier以平衡调节准确率和运算速度的问题。</p>
<p>mobilenetV2中提出新的网络结构inverted residual block。</p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>通过优化网络结构，将mobile net的运算量减少到传统卷积网络的1/9，参数量减少到1/7。</p>
<p>下图为mobile net的“深度可分离卷积”：</p>
<p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4uB1f.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4uB1f.jpg" alt="image-20180912235700174"></a></p>
<p>通过将传统的卷积，分解为 对单个通道的卷积后叠加（而非相加）再执行1x1卷积，减少参数量同时多增加一次batchnorm和relu运算，增加非线性。</p>
<p>并不是稀疏矩阵就一定会比稠密矩阵运算快，但MobileNet将大部分运算集中在1x1卷积中（95%），可以直接调用General Matrix Multiply Funciton(GEMM)，反正就是很快。</p>
<h2 id="新增两个超参数"><a href="#新增两个超参数" class="headerlink" title="新增两个超参数"></a>新增两个超参数</h2><h3 id="Width-multiplier"><a href="#Width-multiplier" class="headerlink" title="Width multiplier"></a>Width multiplier</h3><p>相当于压缩depthwise seperable Conv的kernel数，可以压缩计算过程中的通道数。</p>
<h3 id="Resolution-multiplier"><a href="#Resolution-multiplier" class="headerlink" title="Resolution multiplier"></a>Resolution multiplier</h3><p>压缩feature map的尺寸，可以减少每层的输入尺寸，计算量以平方级别减少。</p>
<h2 id="MobileNetV2"><a href="#MobileNetV2" class="headerlink" title="MobileNetV2"></a>MobileNetV2</h2><p>文章引入了manifold的概念，认为高维度空间的信息是可以被映射(encode)到低维度空间的。</p>
<p>V1就是利用较少的通道数，让空间复杂度降低。width multiplier可以调整feature map的空间维度，让manifold充满(saturate?sapn?)feature map。但是这个方法有时候会失效：对一个1维直线使用ReLU，会输出一条2维的射线；对于n维空间，就会产生有n个结点的曲线。（不确定理解是否有误）</p>
<p>2个可以确定高维度activation space可以映射到低维度子空间的条件：</p>
<ol>
<li>activation space经过RuLU的<strong>非线性</strong>变换之后仍为非零，则这个变换存在一个对应的<strong>线性</strong>变换。</li>
<li>仅当activation space可以映射到低维度的时候，ReLU才可能保留input space的所有信息。</li>
</ol>
<h2 id="Inverted-Residual-Block"><a href="#Inverted-Residual-Block" class="headerlink" title="Inverted Residual Block"></a>Inverted Residual Block</h2><p><a target="_blank" rel="noopener" href="https://s2.ax1x.com/2019/05/12/E4u09P.jpg"><img src="https://s2.ax1x.com/2019/05/12/E4u09P.jpg" alt="InvertedResidualBlock"></a></p>
<p>residual connection是为了优化多层网络时的梯度</p>
<ul>
<li>中间层深度为0时，这个block就是identity function</li>
<li>中间层深度为input深度时，这个block就是传统的resBlock</li>
<li>中间层深度大于input深度是，效果最好（更高维度的特征表示，更稀疏，耦合更少，更好训练？）</li>
</ul>
<p>V2的论文同样引入一个新的hyper parameter用于调节中间层深度与输入层深度的ratio，试验结果同样是非常快，非常准。</p>
<h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>以上为个人理解总结，部分结论不一定正确。</p>
<p>欢迎指出我的错误。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/09/17/MobileNet%E6%A6%82%E8%A7%88/" data-id="cktob6bus0001qgtk4q28ftvi" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/09/17/test-blog/">test_blog</a>
          </li>
        
          <li>
            <a href="/2021/09/17/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2021/09/17/SuperResolution%20by%20FSRCNN/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/09/17/%E5%9C%A8macOS%E5%AE%89%E8%A3%85OpenCV%E4%BB%A5%E5%8F%8AVScode%E7%9A%84%E8%AE%BE%E7%BD%AE/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/09/17/tfRecord%20%E6%90%AC%E8%BF%90/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>